+ export CUDA_DEVICE_MAX_CONNECTIONS=32
+ CUDA_DEVICE_MAX_CONNECTIONS=32
+ srun -p h01 -N 4 --ntasks-per-node=8 --gres=gpu:8 --mem 256G -K -w 'g[40,42,44,46]' -c 13 ./scripts/runtime/bench_dist_attn.sh python bench_dist_attn.py
GpuFreq=control_disabled
GpuFreq=control_disabled
GpuFreq=control_disabled
GpuFreq=control_disabled
Sqkvs: [256, 512, 1024, 2048, 4096, 8192, 16384]
total_size: 30299652096
[rank17]:[W113 02:22:38.935744113 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 17]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank18]:[W113 02:22:38.935995197 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 18]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank3]:[W113 02:22:37.202542381 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank21]:[W113 02:22:38.936614716 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 21]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank2]:[W113 02:22:37.202802411 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank19]:[W113 02:22:38.971462703 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 19]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
causal=False, fob=0:
da_config: SP=(4,8),Sg=(256,256),S=(8192,8192),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
[rank23]:[W113 02:22:38.007536679 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 23]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank22]:[W113 02:22:38.007763086 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 22]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank20]:[W113 02:22:38.009350954 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 20]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank1]:[W113 02:22:37.276226628 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank4]:[W113 02:22:37.276230790 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank7]:[W113 02:22:37.276176382 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank0]:[W113 02:22:37.276555744 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank6]:[W113 02:22:37.276589460 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank5]:[W113 02:22:37.277956939 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank16]:[W113 02:22:38.013138386 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 16]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank24]:[W113 02:22:34.809586651 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 24]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank25]:[W113 02:22:34.809623573 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 25]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank26]:[W113 02:22:34.809567630 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 26]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank27]:[W113 02:22:34.809594998 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 27]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank28]:[W113 02:22:34.809600036 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 28]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank29]:[W113 02:22:34.809574002 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 29]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank31]:[W113 02:22:34.809549390 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 31]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank30]:[W113 02:22:34.811568617 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 30]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank9]:[W113 02:22:37.205589875 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 9]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank10]:[W113 02:22:37.205679094 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 10]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank11]:[W113 02:22:37.205643748 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 11]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank12]:[W113 02:22:37.205680332 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 12]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank13]:[W113 02:22:37.205630834 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 13]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank14]:[W113 02:22:37.205649913 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 14]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank15]:[W113 02:22:37.205652165 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 15]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank8]:[W113 02:22:37.207634583 ProcessGroupNCCL.cpp:4563] [PG ID 0 PG GUID 0 Rank 8]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
# ring_flash_attn_func, fwd
mfu: 0.064 Tflops/s, hfu: 0.064 Tflops/s, 59.606 iter/s, 1.678e-02 s/iter, (15.443, 0.006, 0.067) sec
# orchestrated_attn_func
mfu: 1.188 Tflops/s, hfu: 1.188 Tflops/s, 1106.185 iter/s, 9.040e-04 s/iter, (33.136, 0.004, 0.004) sec
mfu: 1.482 Tflops/s, hfu: 1.482 Tflops/s, 1380.407 iter/s, 7.244e-04 s/iter, (0.113, 0.001, 0.003) sec
mfu: 1.781 Tflops/s, hfu: 1.781 Tflops/s, 1658.837 iter/s, 6.028e-04 s/iter, (0.110, 0.001, 0.002) sec
mfu: 2.38 Tflops/s, hfu: 2.38 Tflops/s, 2216.351 iter/s, 4.512e-04 s/iter, (4.790, 0.002, 0.002) sec
mfu: 2.44 Tflops/s, hfu: 2.44 Tflops/s, 2272.893 iter/s, 4.400e-04 s/iter, (2.958, 0.002, 0.002) sec
mfu: 3.375 Tflops/s, hfu: 3.375 Tflops/s, 3143.073 iter/s, 3.182e-04 s/iter, (0.102, 0.002, 0.001) sec
da_config: SP=(4,8),Sg=(512,512),S=(16384,16384),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, fwd
mfu: 0.268 Tflops/s, hfu: 0.268 Tflops/s, 62.397 iter/s, 1.603e-02 s/iter, (0.035, 0.003, 0.064) sec
# orchestrated_attn_func
mfu: 5.17 Tflops/s, hfu: 5.17 Tflops/s, 1203.671 iter/s, 8.308e-04 s/iter, (0.116, 0.001, 0.003) sec
mfu: 5.581 Tflops/s, hfu: 5.581 Tflops/s, 1299.430 iter/s, 7.696e-04 s/iter, (0.108, 0.002, 0.003) sec
mfu: 6.398 Tflops/s, hfu: 6.398 Tflops/s, 1489.727 iter/s, 6.713e-04 s/iter, (0.106, 0.001, 0.003) sec
mfu: 6.402 Tflops/s, hfu: 6.402 Tflops/s, 1490.491 iter/s, 6.709e-04 s/iter, (0.107, 0.002, 0.003) sec
mfu: 9.979 Tflops/s, hfu: 9.979 Tflops/s, 2323.420 iter/s, 4.304e-04 s/iter, (0.107, 0.002, 0.002) sec
mfu: 18.502 Tflops/s, hfu: 18.502 Tflops/s, 4307.820 iter/s, 2.321e-04 s/iter, (0.102, 0.001, 0.001) sec
da_config: SP=(4,8),Sg=(1024,1024),S=(32768,32768),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, fwd
mfu: 1.114 Tflops/s, hfu: 1.114 Tflops/s, 64.817 iter/s, 1.543e-02 s/iter, (0.031, 0.004, 0.062) sec
# orchestrated_attn_func
mfu: 18.812 Tflops/s, hfu: 18.812 Tflops/s, 1095.022 iter/s, 9.132e-04 s/iter, (0.113, 0.001, 0.004) sec
mfu: 20.886 Tflops/s, hfu: 20.886 Tflops/s, 1215.752 iter/s, 8.225e-04 s/iter, (0.106, 0.002, 0.003) sec
mfu: 19.271 Tflops/s, hfu: 19.271 Tflops/s, 1121.700 iter/s, 8.915e-04 s/iter, (0.104, 0.002, 0.004) sec
mfu: 37.881 Tflops/s, hfu: 37.881 Tflops/s, 2204.974 iter/s, 4.535e-04 s/iter, (0.102, 0.001, 0.002) sec
mfu: 30.385 Tflops/s, hfu: 30.385 Tflops/s, 1768.634 iter/s, 5.654e-04 s/iter, (0.103, 0.002, 0.002) sec
mfu: 56.881 Tflops/s, hfu: 56.881 Tflops/s, 3310.908 iter/s, 3.020e-04 s/iter, (0.102, 0.001, 0.001) sec
da_config: SP=(4,8),Sg=(2048,2048),S=(65536,65536),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, fwd
mfu: 6.975 Tflops/s, hfu: 6.975 Tflops/s, 101.501 iter/s, 9.852e-03 s/iter, (0.022, 0.001, 0.039) sec
# orchestrated_attn_func
mfu: 60.867 Tflops/s, hfu: 60.867 Tflops/s, 885.727 iter/s, 1.129e-03 s/iter, (0.107, 0.001, 0.005) sec
mfu: 59.309 Tflops/s, hfu: 59.309 Tflops/s, 863.063 iter/s, 1.159e-03 s/iter, (0.104, 0.001, 0.005) sec
mfu: 68.904 Tflops/s, hfu: 68.904 Tflops/s, 1002.679 iter/s, 9.973e-04 s/iter, (0.106, 0.001, 0.004) sec
mfu: 79.647 Tflops/s, hfu: 79.647 Tflops/s, 1159.017 iter/s, 8.628e-04 s/iter, (0.103, 0.002, 0.003) sec
mfu: 95.454 Tflops/s, hfu: 95.454 Tflops/s, 1389.043 iter/s, 7.199e-04 s/iter, (0.103, 0.002, 0.003) sec
mfu: 133.082 Tflops/s, hfu: 133.082 Tflops/s, 1936.604 iter/s, 5.164e-04 s/iter, (0.103, 0.001, 0.002) sec
da_config: SP=(4,8),Sg=(4096,4096),S=(131072,131072),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, fwd
mfu: 29.599 Tflops/s, hfu: 29.599 Tflops/s, 107.680 iter/s, 9.287e-03 s/iter, (0.022, 0.001, 0.037) sec
# orchestrated_attn_func
mfu: 126.369 Tflops/s, hfu: 126.369 Tflops/s, 459.728 iter/s, 2.175e-03 s/iter, (0.109, 0.001, 0.009) sec
mfu: 130.907 Tflops/s, hfu: 130.907 Tflops/s, 476.236 iter/s, 2.100e-03 s/iter, (0.108, 0.001, 0.008) sec
mfu: 142.67 Tflops/s, hfu: 142.67 Tflops/s, 519.030 iter/s, 1.927e-03 s/iter, (0.106, 0.001, 0.008) sec
mfu: 177.96 Tflops/s, hfu: 177.96 Tflops/s, 647.413 iter/s, 1.545e-03 s/iter, (0.104, 0.001, 0.006) sec
mfu: 171.762 Tflops/s, hfu: 171.762 Tflops/s, 624.866 iter/s, 1.600e-03 s/iter, (0.104, 0.001, 0.006) sec
mfu: 242.013 Tflops/s, hfu: 242.013 Tflops/s, 880.437 iter/s, 1.136e-03 s/iter, (0.104, 0.001, 0.005) sec
da_config: SP=(4,8),Sg=(8192,8192),S=(262144,262144),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, fwd
mfu: 79.461 Tflops/s, hfu: 79.461 Tflops/s, 72.269 iter/s, 1.384e-02 s/iter, (0.033, 0.004, 0.055) sec
# orchestrated_attn_func
mfu: 179.537 Tflops/s, hfu: 179.537 Tflops/s, 163.288 iter/s, 6.124e-03 s/iter, (0.116, 0.001, 0.024) sec
mfu: 179.934 Tflops/s, hfu: 179.934 Tflops/s, 163.649 iter/s, 6.111e-03 s/iter, (0.114, 0.002, 0.024) sec
mfu: 219.96 Tflops/s, hfu: 219.96 Tflops/s, 200.052 iter/s, 4.999e-03 s/iter, (0.112, 0.002, 0.020) sec
mfu: 244.583 Tflops/s, hfu: 244.583 Tflops/s, 222.447 iter/s, 4.495e-03 s/iter, (0.111, 0.001, 0.018) sec
mfu: 268.291 Tflops/s, hfu: 268.291 Tflops/s, 244.009 iter/s, 4.098e-03 s/iter, (0.110, 0.002, 0.016) sec
mfu: 312.767 Tflops/s, hfu: 312.767 Tflops/s, 284.460 iter/s, 3.515e-03 s/iter, (0.109, 0.001, 0.014) sec
da_config: SP=(4,8),Sg=(16384,16384),S=(524288,524288),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, fwd
mfu: 223.06 Tflops/s, hfu: 223.06 Tflops/s, 50.718 iter/s, 1.972e-02 s/iter, (0.042, 0.001, 0.079) sec
# orchestrated_attn_func
mfu: 204.955 Tflops/s, hfu: 204.955 Tflops/s, 46.601 iter/s, 2.146e-02 s/iter, (0.142, 0.002, 0.086) sec
mfu: 204.687 Tflops/s, hfu: 204.687 Tflops/s, 46.540 iter/s, 2.149e-02 s/iter, (0.143, 0.001, 0.086) sec
mfu: 294.123 Tflops/s, hfu: 294.123 Tflops/s, 66.876 iter/s, 1.495e-02 s/iter, (0.135, 0.001, 0.060) sec
mfu: 286.557 Tflops/s, hfu: 286.557 Tflops/s, 65.155 iter/s, 1.535e-02 s/iter, (0.133, 0.002, 0.061) sec
mfu: 332.515 Tflops/s, hfu: 332.515 Tflops/s, 75.605 iter/s, 1.323e-02 s/iter, (0.129, 0.001, 0.053) sec
mfu: 347.805 Tflops/s, hfu: 347.805 Tflops/s, 79.082 iter/s, 1.265e-02 s/iter, (0.127, 0.002, 0.051) sec
da_config: SP=(4,8),Sg=(256,256),S=(8192,8192),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, fwd
mfu: 2.53 Tflops/s, hfu: 2.53 Tflops/s, 73.632 iter/s, 1.358e-02 s/iter, (0.033, 0.004, 0.054) sec
# orchestrated_attn_func
mfu: 22.317 Tflops/s, hfu: 22.317 Tflops/s, 649.523 iter/s, 1.540e-03 s/iter, (0.108, 0.001, 0.006) sec
mfu: 22.874 Tflops/s, hfu: 22.874 Tflops/s, 665.708 iter/s, 1.502e-03 s/iter, (0.106, 0.001, 0.006) sec
mfu: 23.796 Tflops/s, hfu: 23.796 Tflops/s, 692.563 iter/s, 1.444e-03 s/iter, (0.106, 0.001, 0.006) sec
mfu: 27.446 Tflops/s, hfu: 27.446 Tflops/s, 798.773 iter/s, 1.252e-03 s/iter, (0.105, 0.001, 0.005) sec
mfu: 27.731 Tflops/s, hfu: 27.731 Tflops/s, 807.087 iter/s, 1.239e-03 s/iter, (0.104, 0.001, 0.005) sec
mfu: 36.874 Tflops/s, hfu: 36.874 Tflops/s, 1073.182 iter/s, 9.318e-04 s/iter, (0.106, 0.001, 0.004) sec
da_config: SP=(4,8),Sg=(512,512),S=(16384,16384),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, fwd
mfu: 11.144 Tflops/s, hfu: 11.144 Tflops/s, 81.083 iter/s, 1.233e-02 s/iter, (0.028, 0.001, 0.049) sec
# orchestrated_attn_func
mfu: 56.841 Tflops/s, hfu: 56.841 Tflops/s, 413.573 iter/s, 2.418e-03 s/iter, (0.108, 0.001, 0.010) sec
mfu: 56.57 Tflops/s, hfu: 56.57 Tflops/s, 411.603 iter/s, 2.430e-03 s/iter, (0.107, 0.002, 0.010) sec
mfu: 65.369 Tflops/s, hfu: 65.369 Tflops/s, 475.622 iter/s, 2.103e-03 s/iter, (0.110, 0.001, 0.008) sec
mfu: 56.364 Tflops/s, hfu: 56.364 Tflops/s, 410.105 iter/s, 2.438e-03 s/iter, (0.108, 0.001, 0.010) sec
mfu: 76.019 Tflops/s, hfu: 76.019 Tflops/s, 553.112 iter/s, 1.808e-03 s/iter, (0.106, 0.002, 0.007) sec
mfu: 80.562 Tflops/s, hfu: 80.562 Tflops/s, 586.169 iter/s, 1.706e-03 s/iter, (0.109, 0.001, 0.007) sec
da_config: SP=(4,8),Sg=(1024,1024),S=(32768,32768),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, fwd
mfu: 23.727 Tflops/s, hfu: 23.727 Tflops/s, 43.160 iter/s, 2.317e-02 s/iter, (0.051, 0.001, 0.093) sec
# orchestrated_attn_func
mfu: 127.53 Tflops/s, hfu: 127.53 Tflops/s, 231.976 iter/s, 4.311e-03 s/iter, (0.113, 0.001, 0.017) sec
mfu: 132.332 Tflops/s, hfu: 132.332 Tflops/s, 240.711 iter/s, 4.154e-03 s/iter, (0.114, 0.002, 0.017) sec
mfu: 132.098 Tflops/s, hfu: 132.098 Tflops/s, 240.286 iter/s, 4.162e-03 s/iter, (0.110, 0.001, 0.017) sec
mfu: 114.184 Tflops/s, hfu: 114.184 Tflops/s, 207.700 iter/s, 4.815e-03 s/iter, (0.112, 0.001, 0.019) sec
mfu: 111.918 Tflops/s, hfu: 111.918 Tflops/s, 203.577 iter/s, 4.912e-03 s/iter, (0.112, 0.001, 0.020) sec
mfu: 165.617 Tflops/s, hfu: 165.617 Tflops/s, 301.256 iter/s, 3.319e-03 s/iter, (0.111, 0.001, 0.013) sec
da_config: SP=(4,8),Sg=(2048,2048),S=(65536,65536),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, fwd
mfu: 44.981 Tflops/s, hfu: 44.981 Tflops/s, 20.455 iter/s, 4.889e-02 s/iter, (0.102, 0.001, 0.196) sec
# orchestrated_attn_func
mfu: 174.983 Tflops/s, hfu: 174.983 Tflops/s, 79.573 iter/s, 1.257e-02 s/iter, (0.132, 0.002, 0.050) sec
mfu: 176.61 Tflops/s, hfu: 176.61 Tflops/s, 80.313 iter/s, 1.245e-02 s/iter, (0.131, 0.002, 0.050) sec
mfu: 187.448 Tflops/s, hfu: 187.448 Tflops/s, 85.241 iter/s, 1.173e-02 s/iter, (0.127, 0.001, 0.047) sec
mfu: 186.95 Tflops/s, hfu: 186.95 Tflops/s, 85.015 iter/s, 1.176e-02 s/iter, (0.126, 0.001, 0.047) sec
mfu: 201.889 Tflops/s, hfu: 201.889 Tflops/s, 91.808 iter/s, 1.089e-02 s/iter, (0.125, 0.001, 0.044) sec
mfu: 247.457 Tflops/s, hfu: 247.457 Tflops/s, 112.531 iter/s, 8.886e-03 s/iter, (0.121, 0.001, 0.036) sec
da_config: SP=(4,8),Sg=(4096,4096),S=(131072,131072),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, fwd
mfu: 81.533 Tflops/s, hfu: 81.533 Tflops/s, 9.269 iter/s, 1.079e-01 s/iter, (0.218, 0.003, 0.432) sec
# orchestrated_attn_func
mfu: 316.31 Tflops/s, hfu: 316.31 Tflops/s, 35.960 iter/s, 2.781e-02 s/iter, (0.163, 0.001, 0.111) sec
mfu: 320.243 Tflops/s, hfu: 320.243 Tflops/s, 36.407 iter/s, 2.747e-02 s/iter, (0.159, 0.001, 0.110) sec
mfu: 326.133 Tflops/s, hfu: 326.133 Tflops/s, 37.077 iter/s, 2.697e-02 s/iter, (0.157, 0.001, 0.108) sec
mfu: 253.554 Tflops/s, hfu: 253.554 Tflops/s, 28.826 iter/s, 3.469e-02 s/iter, (0.172, 0.002, 0.139) sec
mfu: 273.105 Tflops/s, hfu: 273.105 Tflops/s, 31.048 iter/s, 3.221e-02 s/iter, (0.173, 0.002, 0.129) sec
mfu: 314.287 Tflops/s, hfu: 314.287 Tflops/s, 35.730 iter/s, 2.799e-02 s/iter, (0.166, 0.002, 0.112) sec
da_config: SP=(4,8),Sg=(8192,8192),S=(262144,262144),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, fwd
mfu: 137.839 Tflops/s, hfu: 137.839 Tflops/s, 3.918 iter/s, 2.553e-01 s/iter, (0.517, 0.003, 1.021) sec
# orchestrated_attn_func
mfu: 356.592 Tflops/s, hfu: 356.592 Tflops/s, 10.135 iter/s, 9.867e-02 s/iter, (0.308, 0.002, 0.395) sec
mfu: 356.203 Tflops/s, hfu: 356.203 Tflops/s, 10.124 iter/s, 9.878e-02 s/iter, (0.303, 0.001, 0.395) sec
mfu: 370.918 Tflops/s, hfu: 370.918 Tflops/s, 10.542 iter/s, 9.486e-02 s/iter, (0.301, 0.004, 0.379) sec
mfu: 309.402 Tflops/s, hfu: 309.402 Tflops/s, 8.794 iter/s, 1.137e-01 s/iter, (0.333, 0.001, 0.455) sec
mfu: 312.979 Tflops/s, hfu: 312.979 Tflops/s, 8.895 iter/s, 1.124e-01 s/iter, (0.333, 0.002, 0.450) sec
mfu: 338.478 Tflops/s, hfu: 338.478 Tflops/s, 9.620 iter/s, 1.039e-01 s/iter, (0.321, 0.001, 0.416) sec
da_config: SP=(4,8),Sg=(16384,16384),S=(524288,524288),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, fwd
mfu: 203.589 Tflops/s, hfu: 203.589 Tflops/s, 1.447 iter/s, 6.913e-01 s/iter, (1.401, 0.004, 2.765) sec
# orchestrated_attn_func
mfu: 363.498 Tflops/s, hfu: 363.498 Tflops/s, 2.583 iter/s, 3.872e-01 s/iter, (0.890, 0.004, 1.549) sec
mfu: 361.042 Tflops/s, hfu: 361.042 Tflops/s, 2.565 iter/s, 3.898e-01 s/iter, (0.884, 0.004, 1.559) sec
mfu: 375.49 Tflops/s, hfu: 375.49 Tflops/s, 2.668 iter/s, 3.748e-01 s/iter, (0.869, 0.003, 1.499) sec
mfu: 324.276 Tflops/s, hfu: 324.276 Tflops/s, 2.304 iter/s, 4.340e-01 s/iter, (0.967, 0.002, 1.736) sec
mfu: 336.186 Tflops/s, hfu: 336.186 Tflops/s, 2.389 iter/s, 4.186e-01 s/iter, (0.953, 0.004, 1.675) sec
mfu: 375.063 Tflops/s, hfu: 375.063 Tflops/s, 2.665 iter/s, 3.752e-01 s/iter, (0.878, 0.005, 1.501) sec
causal=False, fob=1:
da_config: SP=(4,8),Sg=(256,256),S=(8192,8192),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 0.141 Tflops/s, hfu: 0.176 Tflops/s, 65.655 iter/s, 1.523e-02 s/iter, (0.032, 0.001, 0.061) sec
# orchestrated_attn_func
mfu: 1.638 Tflops/s, hfu: 2.048 Tflops/s, 762.986 iter/s, 1.311e-03 s/iter, (0.187, 0.001, 0.005) sec
mfu: 1.606 Tflops/s, hfu: 2.008 Tflops/s, 748.019 iter/s, 1.337e-03 s/iter, (0.107, 0.001, 0.005) sec
mfu: 1.604 Tflops/s, hfu: 2.005 Tflops/s, 746.844 iter/s, 1.339e-03 s/iter, (0.109, 0.001, 0.005) sec
mfu: 3.792 Tflops/s, hfu: 4.74 Tflops/s, 1765.811 iter/s, 5.663e-04 s/iter, (0.105, 0.001, 0.002) sec
mfu: 4.288 Tflops/s, hfu: 5.36 Tflops/s, 1996.646 iter/s, 5.008e-04 s/iter, (0.101, 0.002, 0.002) sec
mfu: 3.653 Tflops/s, hfu: 4.566 Tflops/s, 1701.004 iter/s, 5.879e-04 s/iter, (0.102, 0.001, 0.002) sec
da_config: SP=(4,8),Sg=(512,512),S=(16384,16384),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 0.559 Tflops/s, hfu: 0.699 Tflops/s, 65.079 iter/s, 1.537e-02 s/iter, (0.028, 0.002, 0.061) sec
# orchestrated_attn_func
mfu: 4.845 Tflops/s, hfu: 6.056 Tflops/s, 564.036 iter/s, 1.773e-03 s/iter, (0.106, 0.001, 0.007) sec
mfu: 4.544 Tflops/s, hfu: 5.68 Tflops/s, 528.982 iter/s, 1.890e-03 s/iter, (0.110, 0.001, 0.008) sec
mfu: 4.9 Tflops/s, hfu: 6.125 Tflops/s, 570.393 iter/s, 1.753e-03 s/iter, (0.110, 0.001, 0.007) sec
mfu: 12.997 Tflops/s, hfu: 16.246 Tflops/s, 1513.061 iter/s, 6.609e-04 s/iter, (0.105, 0.001, 0.003) sec
mfu: 14.672 Tflops/s, hfu: 18.34 Tflops/s, 1708.070 iter/s, 5.855e-04 s/iter, (0.103, 0.001, 0.002) sec
mfu: 15.925 Tflops/s, hfu: 19.906 Tflops/s, 1853.857 iter/s, 5.394e-04 s/iter, (2.592, 0.001, 0.002) sec
da_config: SP=(4,8),Sg=(1024,1024),S=(32768,32768),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 1.511 Tflops/s, hfu: 1.889 Tflops/s, 43.979 iter/s, 2.274e-02 s/iter, (0.046, 0.004, 0.091) sec
# orchestrated_attn_func
mfu: 12.085 Tflops/s, hfu: 15.106 Tflops/s, 351.715 iter/s, 2.843e-03 s/iter, (0.121, 0.002, 0.011) sec
mfu: 12.042 Tflops/s, hfu: 15.053 Tflops/s, 350.469 iter/s, 2.853e-03 s/iter, (0.111, 0.001, 0.011) sec
mfu: 12.137 Tflops/s, hfu: 15.171 Tflops/s, 353.225 iter/s, 2.831e-03 s/iter, (0.109, 0.001, 0.011) sec
mfu: 36.687 Tflops/s, hfu: 45.858 Tflops/s, 1067.719 iter/s, 9.366e-04 s/iter, (0.103, 0.001, 0.004) sec
mfu: 37.54 Tflops/s, hfu: 46.926 Tflops/s, 1092.571 iter/s, 9.153e-04 s/iter, (0.103, 0.001, 0.004) sec
mfu: 38.253 Tflops/s, hfu: 47.816 Tflops/s, 1113.308 iter/s, 8.982e-04 s/iter, (0.102, 0.001, 0.004) sec
da_config: SP=(4,8),Sg=(2048,2048),S=(65536,65536),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 8.436 Tflops/s, hfu: 10.545 Tflops/s, 61.377 iter/s, 1.629e-02 s/iter, (0.032, 0.002, 0.065) sec
# orchestrated_attn_func
mfu: 28.07 Tflops/s, hfu: 35.088 Tflops/s, 204.239 iter/s, 4.896e-03 s/iter, (0.123, 0.001, 0.020) sec
mfu: 27.273 Tflops/s, hfu: 34.091 Tflops/s, 198.435 iter/s, 5.039e-03 s/iter, (0.114, 0.002, 0.020) sec
mfu: 28.105 Tflops/s, hfu: 35.131 Tflops/s, 204.490 iter/s, 4.890e-03 s/iter, (0.114, 0.002, 0.020) sec
mfu: 113.826 Tflops/s, hfu: 142.282 Tflops/s, 828.193 iter/s, 1.207e-03 s/iter, (0.106, 0.001, 0.005) sec
mfu: 93.8 Tflops/s, hfu: 117.25 Tflops/s, 682.482 iter/s, 1.465e-03 s/iter, (0.104, 0.001, 0.006) sec
mfu: 94.07 Tflops/s, hfu: 117.587 Tflops/s, 684.448 iter/s, 1.461e-03 s/iter, (0.104, 0.001, 0.006) sec
da_config: SP=(4,8),Sg=(4096,4096),S=(131072,131072),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 36.132 Tflops/s, hfu: 45.166 Tflops/s, 65.724 iter/s, 1.522e-02 s/iter, (0.029, 0.001, 0.061) sec
# orchestrated_attn_func
mfu: 60.878 Tflops/s, hfu: 76.097 Tflops/s, 110.736 iter/s, 9.030e-03 s/iter, (0.131, 0.001, 0.036) sec
mfu: 61.14 Tflops/s, hfu: 76.425 Tflops/s, 111.213 iter/s, 8.992e-03 s/iter, (0.124, 0.001, 0.036) sec
mfu: 60.479 Tflops/s, hfu: 75.598 Tflops/s, 110.010 iter/s, 9.090e-03 s/iter, (0.120, 0.001, 0.036) sec
mfu: 177.468 Tflops/s, hfu: 221.835 Tflops/s, 322.813 iter/s, 3.098e-03 s/iter, (0.109, 0.001, 0.012) sec
mfu: 159.511 Tflops/s, hfu: 199.388 Tflops/s, 290.148 iter/s, 3.447e-03 s/iter, (0.109, 0.002, 0.014) sec
mfu: 154.179 Tflops/s, hfu: 192.724 Tflops/s, 280.451 iter/s, 3.566e-03 s/iter, (0.110, 0.001, 0.014) sec
da_config: SP=(4,8),Sg=(8192,8192),S=(262144,262144),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 109.78 Tflops/s, hfu: 137.226 Tflops/s, 49.922 iter/s, 2.003e-02 s/iter, (0.040, 0.001, 0.080) sec
# orchestrated_attn_func
mfu: 126.332 Tflops/s, hfu: 157.915 Tflops/s, 57.449 iter/s, 1.741e-02 s/iter, (0.142, 0.001, 0.070) sec
mfu: 126.805 Tflops/s, hfu: 158.506 Tflops/s, 57.664 iter/s, 1.734e-02 s/iter, (0.140, 0.001, 0.069) sec
mfu: 126.437 Tflops/s, hfu: 158.046 Tflops/s, 57.497 iter/s, 1.739e-02 s/iter, (0.141, 0.001, 0.070) sec
mfu: 212.972 Tflops/s, hfu: 266.215 Tflops/s, 96.849 iter/s, 1.033e-02 s/iter, (0.125, 0.002, 0.041) sec
mfu: 216.114 Tflops/s, hfu: 270.143 Tflops/s, 98.277 iter/s, 1.018e-02 s/iter, (0.122, 0.001, 0.041) sec
mfu: 209.651 Tflops/s, hfu: 262.064 Tflops/s, 95.338 iter/s, 1.049e-02 s/iter, (0.123, 0.001, 0.042) sec
da_config: SP=(4,8),Sg=(16384,16384),S=(524288,524288),Nh=(1,1),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 192.532 Tflops/s, hfu: 240.665 Tflops/s, 21.888 iter/s, 4.569e-02 s/iter, (0.097, 0.004, 0.183) sec
# orchestrated_attn_func
mfu: 151.079 Tflops/s, hfu: 188.849 Tflops/s, 17.176 iter/s, 5.822e-02 s/iter, (0.230, 0.002, 0.233) sec
mfu: 149.822 Tflops/s, hfu: 187.277 Tflops/s, 17.033 iter/s, 5.871e-02 s/iter, (0.230, 0.002, 0.235) sec
mfu: 153.209 Tflops/s, hfu: 191.512 Tflops/s, 17.418 iter/s, 5.741e-02 s/iter, (0.220, 0.002, 0.230) sec
mfu: 238.693 Tflops/s, hfu: 298.367 Tflops/s, 27.136 iter/s, 3.685e-02 s/iter, (0.179, 0.001, 0.147) sec
mfu: 233.822 Tflops/s, hfu: 292.278 Tflops/s, 26.582 iter/s, 3.762e-02 s/iter, (0.178, 0.001, 0.150) sec
mfu: 230.279 Tflops/s, hfu: 287.849 Tflops/s, 26.180 iter/s, 3.820e-02 s/iter, (0.178, 0.001, 0.153) sec
da_config: SP=(4,8),Sg=(256,256),S=(8192,8192),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 3.416 Tflops/s, hfu: 4.27 Tflops/s, 49.706 iter/s, 2.012e-02 s/iter, (0.041, 0.001, 0.080) sec
# orchestrated_attn_func
mfu: 32.421 Tflops/s, hfu: 40.526 Tflops/s, 471.787 iter/s, 2.120e-03 s/iter, (0.111, 0.001, 0.008) sec
mfu: 28.657 Tflops/s, hfu: 35.822 Tflops/s, 417.018 iter/s, 2.398e-03 s/iter, (0.108, 0.001, 0.010) sec
mfu: 30.267 Tflops/s, hfu: 37.834 Tflops/s, 440.446 iter/s, 2.270e-03 s/iter, (0.109, 0.002, 0.009) sec
da_config: SP=(4,8),Sg=(512,512),S=(16384,16384),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 7.708 Tflops/s, hfu: 9.635 Tflops/s, 28.041 iter/s, 3.566e-02 s/iter, (0.076, 0.001, 0.143) sec
# orchestrated_attn_func
mfu: 70.784 Tflops/s, hfu: 88.48 Tflops/s, 257.511 iter/s, 3.883e-03 s/iter, (0.112, 0.001, 0.016) sec
mfu: 62.783 Tflops/s, hfu: 78.478 Tflops/s, 228.402 iter/s, 4.378e-03 s/iter, (0.112, 0.001, 0.018) sec
mfu: 68.907 Tflops/s, hfu: 86.133 Tflops/s, 250.681 iter/s, 3.989e-03 s/iter, (0.111, 0.001, 0.016) sec
da_config: SP=(4,8),Sg=(1024,1024),S=(32768,32768),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 15.621 Tflops/s, hfu: 19.526 Tflops/s, 14.207 iter/s, 7.039e-02 s/iter, (0.146, 0.001, 0.282) sec
# orchestrated_attn_func
mfu: 118.206 Tflops/s, hfu: 147.758 Tflops/s, 107.508 iter/s, 9.302e-03 s/iter, (0.135, 0.001, 0.037) sec
mfu: 116.193 Tflops/s, hfu: 145.241 Tflops/s, 105.677 iter/s, 9.463e-03 s/iter, (0.122, 0.001, 0.038) sec
mfu: 119.992 Tflops/s, hfu: 149.99 Tflops/s, 109.132 iter/s, 9.163e-03 s/iter, (0.123, 0.002, 0.037) sec
da_config: SP=(4,8),Sg=(2048,2048),S=(65536,65536),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 31.81 Tflops/s, hfu: 39.763 Tflops/s, 7.233 iter/s, 1.383e-01 s/iter, (0.283, 0.001, 0.553) sec
# orchestrated_attn_func
mfu: 165.717 Tflops/s, hfu: 207.146 Tflops/s, 37.680 iter/s, 2.654e-02 s/iter, (0.168, 0.001, 0.106) sec
mfu: 162.774 Tflops/s, hfu: 203.468 Tflops/s, 37.011 iter/s, 2.702e-02 s/iter, (0.158, 0.002, 0.108) sec
mfu: 162.63 Tflops/s, hfu: 203.287 Tflops/s, 36.978 iter/s, 2.704e-02 s/iter, (0.160, 0.001, 0.108) sec
da_config: SP=(4,8),Sg=(4096,4096),S=(131072,131072),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 63.436 Tflops/s, hfu: 79.296 Tflops/s, 3.606 iter/s, 2.773e-01 s/iter, (0.562, 0.004, 1.109) sec
# orchestrated_attn_func
mfu: 196.006 Tflops/s, hfu: 245.008 Tflops/s, 11.142 iter/s, 8.975e-02 s/iter, (0.327, 0.001, 0.359) sec
mfu: 193.245 Tflops/s, hfu: 241.557 Tflops/s, 10.985 iter/s, 9.104e-02 s/iter, (0.286, 0.002, 0.364) sec
mfu: 197.226 Tflops/s, hfu: 246.532 Tflops/s, 11.211 iter/s, 8.920e-02 s/iter, (0.282, 0.002, 0.357) sec
da_config: SP=(4,8),Sg=(8192,8192),S=(262144,262144),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 102.39 Tflops/s, hfu: 127.988 Tflops/s, 1.455 iter/s, 6.873e-01 s/iter, (1.270, 0.003, 2.749) sec
# orchestrated_attn_func
mfu: 221.087 Tflops/s, hfu: 276.359 Tflops/s, 3.142 iter/s, 3.183e-01 s/iter, (0.810, 0.002, 1.273) sec
mfu: 217.631 Tflops/s, hfu: 272.039 Tflops/s, 3.093 iter/s, 3.233e-01 s/iter, (0.746, 0.001, 1.293) sec
mfu: 217.966 Tflops/s, hfu: 272.458 Tflops/s, 3.097 iter/s, 3.228e-01 s/iter, (0.744, 0.001, 1.291) sec
da_config: SP=(4,8),Sg=(16384,16384),S=(524288,524288),Nh=(32,32),bs=1,D=128,causal=False,hierarchy=1:
YXs: [(1, 4), (2, 2), (4, 1)]
# ring_flash_attn_func, bwd
mfu: 145.104 Tflops/s, hfu: 181.38 Tflops/s, 0.516 iter/s, 1.940e+00 s/iter, (3.825, 0.003, 7.759) sec
# orchestrated_attn_func
mfu: 223.482 Tflops/s, hfu: 279.352 Tflops/s, 0.794 iter/s, 1.259e+00 s/iter, (2.714, 0.004, 5.038) sec
mfu: 223.753 Tflops/s, hfu: 279.691 Tflops/s, 0.795 iter/s, 1.258e+00 s/iter, (2.606, 0.002, 5.032) sec
mfu: 220.961 Tflops/s, hfu: 276.201 Tflops/s, 0.785 iter/s, 1.274e+00 s/iter, (2.625, 0.005, 5.095) sec
+ y
./scripts/runtime/wrapper.sh: line 141: y: command not found
+ set +x
